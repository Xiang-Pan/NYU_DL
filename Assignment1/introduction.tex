The goal of homework 1 is to help you understand the common techniques used in Deep Learning and how to update network parameters by the using backpropagation algorithm.

Part 1 has two sub-parts, 1.1, 1.2, 1.3 majorly deal with the theory of backpropagation algorithm whereas 1.4 is to test conceptual knowledge on deep learning. For part 1.2 and 1.3, you need to answer the questions with mathematical equations. You should put all your answers in a PDF file and we will not accept any scanned hand-written answers. It is recommended to use \LaTeX.

For part 2, you need to program in Python. It requires you to implement your own forward and backward pass without using autograd. You need to submit your \texttt{mlp.py} file for this part.

The due date of homework 1 is \texttt{23:55 EST} of \texttt{02/17}.
Submit the following files in a zip file \texttt{your\_net\_id.zip} through NYU Brightspace:
\begin{itemize}
\item \texttt{theory.pdf}
\item \texttt{mlp.py}
\end{itemize}

The following behaviors will result in penalty of your final score:
\begin{enumerate}
\item 5\% penalty for submitting your files without using the correct format. (including naming the zip file, PDF file or python file wrong, or adding extra files in the zip folder, like the testing scripts from part 2). 
\item 20\% penalty for late submission within the first 24 hours. We will not accept any late submission after the first 24 hours.
\item 20\% penalty for code submission that cannot be executed using the steps we mentioned in part 2.
So please test your code before submit it.
\end{enumerate}





